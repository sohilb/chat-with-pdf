# ğŸ“„ Chat with PDF

**Chat with PDF** is a lightweight Streamlit app that lets you hold naturalâ€‘language conversations with the contents of any PDF document.  
Behind the scenes it spins up a Retrievalâ€‘Augmented Generation (RAG) pipeline powered by [LangChain](https://github.com/langchain-ai/langchain), [OpenAI](https://openai.com/), and an inâ€‘memory [Chroma](https://docs.trychroma.com/) vector store.

![Screenshot](./docs/screenshot.png)

---

## âœ¨ Features

| Capability | Description |
|------------|-------------|
| ğŸš€ **Zeroâ€‘setup PDF chat** | Dragâ€‘andâ€‘drop a PDF, ask questions, get answers. |
| ğŸ§  **Contextâ€‘aware retrieval** | Uses `create_history_aware_retriever` so followâ€‘up questions automatically carry conversation context. |
| ğŸ“š **Chunking & embeddings** | Splits text with `RecursiveCharacterTextSplitter` and embeds with `OpenAIEmbeddings` (or your own). |
| âš¡ **Fast local vector store** | Chroma keeps everything inâ€‘memory; no external DB required. |
| ğŸ” **Envâ€‘based secrets** | API keys read from `.env` â€“ never hardâ€‘coded. |
| ğŸ›  **Portable** | Works everywhere Python runs â€“ deploy on Streamlit Cloud, Docker, or your laptop. |

---

## ğŸ Quickstart

```bash
# 1. Clone
git clone https://github.com/yourâ€‘org/chatâ€‘withâ€‘pdf.git
cd chatâ€‘withâ€‘pdf

# 2. Create & activate virtual env (optional but recommended)
python -m venv .venv
source .venv/bin/activate    # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set your OpenAI key
echo "OPENAI_API_KEY=skâ€‘..." > .env    # or edit manually

# 5. Run the app
streamlit run app.py
```

Then open <http://localhost:8501> in your browser, upload a PDF, and start chatting! âœ¨

---

## ğŸ—‚ï¸ Project Structure

```text
.
â”œâ”€â”€ app.py            # Streamlit UI
â”œâ”€â”€ rag_pipeline.py   # RAG pipeline builder
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration

All environment variables are loaded via **pythonâ€‘dotenv** (`.env` file):

| Variable | Purpose | Required |
|----------|---------|----------|
| `OPENAI_API_KEY` | Your OpenAI API key (used for embeddings & chat model) | âœ… |
| `OPENAI_MODEL` | Chat model name, defaults to `gpt-4o-mini` | optional |
| `EMBEDDING_MODEL` | Embedding model name, defaults to `text-embedding-3-large` | optional |

---

## ğŸ“ Extending

- **Swap Embeddings** â€“ Replace `OpenAIEmbeddings` with `HuggingFaceEmbeddings` for an openâ€‘source stack.
- **Persistent Vector Store** â€“ Point Chroma to a directory (e.g., `persist_directory="db"`) to keep indexes between restarts.
- **Multiâ€‘PDF Support** â€“ Hold multiple vectors in memory and add a selector dropâ€‘down in `app.py`.
- **Download chat history** â€“ Streamlitâ€™s `st.download_button` makes it oneâ€‘liner.

See the inline comments in `rag_pipeline.py` for further pointers.

---

## ğŸ› Troubleshooting

| Problem | Fix |
|---------|-----|
| `ModuleNotFoundError: langchain_community...` | Make sure you installed with `-r requirements.txt`. |
| `RateLimitError` | You may be sending too many requests to OpenAI; lower the `streaming=False`, `temperature=0`, or upgrade your plan. |
| â€œPlease upload a PDF firstâ€ | Ensure `st.session_state.chain` is set (upload succeeded) â€“ see your terminal for any indexing errors. |

---

## ğŸ“¨ License

[MIT](LICENSE)

Made with â¤ï¸ and lots of coffee.
